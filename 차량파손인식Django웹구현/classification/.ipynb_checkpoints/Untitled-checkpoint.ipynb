{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7cc894",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8ce0020271fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)# Import Libraries\n",
    "\n",
    "# For visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from tensorboard.backend.event_processing import event_accumulator as ea\n",
    "\n",
    "# Scipy for calculating distance\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import os, json, cv2, random, time, copy\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체\n",
    "# Set base params\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f89d410",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'register_coco_instances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d6f81ec5015d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"carrs_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./inference/annotations.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./inference/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'register_coco_instances' is not defined"
     ]
    }
   ],
   "source": [
    "register_coco_instances(\"carrs_data\", {}, './inference/annotations.json', './inference/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b780c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # only has one class (damage) + 1\n",
    "        cfg.MODEL.RETINANET.NUM_CLASSES = 4 # only has one class (damage) + 1\n",
    "        #cfg.MODEL.WEIGHTS = os.path.join(\"/home/adminuser/notebooks/01seokhwa/models/model_final.pth\")\n",
    "        cfg.MODEL.WEIGHTS = os.path.join(settings.BASE_DIR,'classification/inference/model/damage_final.pth')\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \n",
    "        cfg['MODEL']['DEVICE']='cuda'#or cpu\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "\n",
    "        damage_class_map= {0:'dent', 1:'scratch'}\n",
    "\n",
    "        dataset = DatasetCatalog.get(\"carrs_data\")\n",
    "        metadata = MetadataCatalog.get(\"carrs_data\")\n",
    "\n",
    "\n",
    "        fig, (ax1) = plt.subplots(1, figsize =(16,12))\n",
    "\n",
    "        img = io.imread(image_path)\n",
    "        model_output = predictor(img)\n",
    "        model_output = model_output[\"instances\"].to(\"cpu\")\n",
    "        # only include detected instances with high enough score\n",
    "        ni = model_output[model_output.pred_classes != 3]\n",
    "        ni = ni[ni.pred_classes != 2]\n",
    "        ni = ni[ni.scores > 0.8]\n",
    "\n",
    "        # use the built-in visualizer to draw the boxes onto the image\n",
    "        v = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"carrs_data\"))\n",
    "        img = v.draw_instance_predictions(model_output).get_image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_detectron2",
   "language": "python",
   "name": "conda-env-py37_detectron2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
